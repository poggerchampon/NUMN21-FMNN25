{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cb205aab-be70-4451-b5bc-a0deb2cf4adb",
      "metadata": {
        "id": "cb205aab-be70-4451-b5bc-a0deb2cf4adb"
      },
      "source": [
        "# Lab: Data Wrangling\n",
        "\n",
        "In this exercise we will extract tabular data from an article published in an online scientific journal. We will touch on the following topics:\n",
        "\n",
        "- Extraction of data from HTML pages\n",
        "- Data cleanup using Pandas\n",
        "- Data visualization\n",
        "- CSV export\n",
        "- FAIR data principles\n",
        "\n",
        "## Extract data from a scientific paper\n",
        "\n",
        "This will extract Table 1 from the scientific paper [_NMR determination of pKa values in α‐synuclein_](https://doi.org/10.1002/pro.556).\n",
        "It is a nice study of the acid dissociation constants of amino acids inside a protein, measured using NMR spectroscopy.\n",
        "\n",
        "The first extraction below is messy, so a bit of cleanup is needed.\n",
        "Note that `pandas` requires that the `lxml` package is installed.\n",
        "To run this, do the following:\n",
        "1. Follow the link to the above paper, assuming you have full-text access\n",
        "2. Save the page as `croke.html` and place it in this folder. The resulting `html` file may vary, depending on what browser (and probably year!) you're downloading. Your teacher may help you obtain a suitable version.\n",
        "3. Run the cell below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "Fhgf6ukF0jO1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Fhgf6ukF0jO1",
        "outputId": "34148a8d-e9bc-42fe-d46f-c1e5c3d98927"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-335261828.py:8: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
            "  df_original = pd.read_html(\"croke.html\")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "No tables found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-335261828.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load HTML using Pandas. If on Colab, you must upload the HTML to your session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf_original\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"croke.html\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_original\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_original\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/html.py\u001b[0m in \u001b[0;36mread_html\u001b[0;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links, dtype_backend, storage_options)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         )\n\u001b[1;32m   1239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m     return _parse(\n\u001b[0m\u001b[1;32m   1241\u001b[0m         \u001b[0mflavor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflavor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m         \u001b[0mio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/html.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m   1001\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mretained\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# for mypy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mretained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/html.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m             \u001b[0mtables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcaught\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;31m# if `io` is an io-like object, check if it's seekable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/html.py\u001b[0m in \u001b[0;36mparse_tables\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mparsed\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfooter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mtuples\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \"\"\"\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mtables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_thead_tbody_tfoot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/html.py\u001b[0m in \u001b[0;36m_parse_tables\u001b[0;34m(self, document, match, attrs)\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0mtables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No tables found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No tables found"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Load HTML using Pandas. If on Colab, you must upload the HTML to your session.\n",
        "df_original = pd.read_html(\"croke.html\")\n",
        "print(df_original)\n",
        "df = pd.DataFrame(df_original[0])\n",
        "df1 = df[\"No salt\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a6d4c68-970c-45f1-babd-f78b47f1851b",
      "metadata": {
        "id": "1a6d4c68-970c-45f1-babd-f78b47f1851b"
      },
      "source": [
        "### Task 0\n",
        "\n",
        "What is the type of `df_original`? We want to focus on the \"No salt\" data set, so go ahead and extract that."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JcYUxMPwaGuV"
      },
      "id": "JcYUxMPwaGuV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "8c40fa28-98b3-40f1-8bb1-a61bedb0c168",
      "metadata": {
        "id": "8c40fa28-98b3-40f1-8bb1-a61bedb0c168"
      },
      "source": [
        "### Task 1\n",
        "\n",
        "The above table cannot be readily processed for various reasons. Firstly, the numbers are actually _strings_ and contain the unicode character `±`.\n",
        "Secondly, values and errors are mixed.\n",
        "Your task is now to cleanup the above table so that it looks something like this (we have only printed the first couple of rows here):\n",
        "\n",
        "pKa   |  err |  resname | resnum\n",
        "----- | ---- | -------- | -----------\n",
        "3.61  | 0.05 | Asp      | 2\n",
        "4.21  | 0.06 | Glu      | 13\n",
        "...   | ...  | ...      | ...\n",
        "\n",
        "In your report, document and motivate your code. Note how the residue name; error; and residue number have been separated to three individual columns.\n",
        "\n",
        "#### Hints:\n",
        "1. Do this in small steps!\n",
        "1. This cleanup is mostly an exercise in how to use Pandas. There's plenty of online information about this and you may search for _\"Delete pandas column\"_ etc.\n",
        "1. Try to run `df.pKa.str.split(\"±\").str.get(0).astype(float)` in a cell. Figure out what each method is doing.\n",
        "1. Columns can be assigned with `df.assign()` or dropped with `df.drop()`.\n",
        "1. Some values in the `Site` column are suffixed by letters `c` and `d`. Use `str.replace()` to get rid of these.\n",
        "1. Combined residue name and number can be split using [_regex_](https://en.wikipedia.org/wiki/Regular_expression), i.e. something like `str.split(\"([A-Za-z]+)(\\d+)\")`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df11 = df1[\"Site\"]\n",
        "#df11[['resname', 'resnum']] = df11.str.split(expand=True)\n",
        "#df11.str.split(\"0|1|2|3|4|5|6|7|8|9\", n=1, expand=True)\n",
        "#df11['resname', 'resnum'] = df11.str[:3], df11.str[3:]\n",
        "#df1.loc[df11, 'Site']\n",
        "df1['resname'] = df1['Site'].str[:3]\n",
        "df1['resnum'] = df1['Site'].str[3:]\n",
        "df1 = df1.drop(columns=['Site'])\n",
        "#df1 = df1.assign(columns=['resname'], )\n",
        "col_list = df1.columns\n",
        "col_list[0], col_list[1], col_list[2], col_list[3], col_list[4], col_list[5] = col_list[4], col_list[5], col_list[0], col_list[1], col_list[2], col_list[3]\n",
        "df1.columns = col_list\n",
        "#df1['Site'] = df1['Site'].str[:3]\n",
        "df1"
      ],
      "metadata": {
        "id": "aVXwImezIC6y",
        "outputId": "ad55d818-9415-408d-f1bd-89eaf9f1728b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "id": "aVXwImezIC6y",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df1' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3842559092.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf11\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Site\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#df11[['resname', 'resnum']] = df11.str.split(expand=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#df11.str.split(\"0|1|2|3|4|5|6|7|8|9\", n=1, expand=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#df11['resname', 'resnum'] = df11.str[:3], df11.str[3:]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#df1.loc[df11, 'Site']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc5a938b-a780-477b-a427-438a14e16345",
      "metadata": {
        "id": "dc5a938b-a780-477b-a427-438a14e16345"
      },
      "source": [
        "### Task 2\n",
        "\n",
        "Export the above data to a `CSV` file. Motivate why or why not this is a good idea?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1f7f7be-5d69-4da7-86f0-ff0fdb9dae84",
      "metadata": {
        "id": "a1f7f7be-5d69-4da7-86f0-ff0fdb9dae84"
      },
      "source": [
        "### Task 3\n",
        "\n",
        "The acid dissocitation constant of an isolated glutamic acid (\"Glu\") is p$K_a^0$=4.1.\n",
        "As a function of residue number, plot the shift from this reference value for all glutamates in the above tabel.\n",
        "_Hints:_ Use `matplotlib` and a `pandas` mask using _e.g._ `mask = df.resname == \"Glu\"`.\n",
        "Your plot could look something like the following:\n",
        "\n",
        "![Screenshot 2024-09-16 at 10.25.32.png](attachment:c78e7661-e295-439a-9f99-06a237807946.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a59739ed-5fb3-4c80-8ee3-21164a36dcc7",
      "metadata": {
        "id": "a59739ed-5fb3-4c80-8ee3-21164a36dcc7"
      },
      "source": [
        "## Report\n",
        "\n",
        "The report should be based on this Notebook and should in addition to answers to the above tasks include a discussion about how the original paper relates to the FAIR data principles. Detail how your workflow is an improvement with regard to the FAIR principles."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}